{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d96bb308-9eec-43e5-8938-6ac117211d5e",
   "metadata": {},
   "source": [
    "## DRAGON *DualFinder*: An Instance of the DRAGON CNN Architecture Specialized for Dual AGN Detection.\n",
    "### Authors: Isaac Moskowitz and Jeremy Ng\n",
    "### Collaborators: C. Meg Urry (PI), Aritra Ghosh. \n",
    "#### Began June 7, 2024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2275783a-1754-488b-bf1b-0e0d2bb08cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-14 09:48:31.735435: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-14 09:48:32.532198: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-14 09:48:32.532245: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-14 09:48:32.537731: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-14 09:48:32.940995: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-14 09:48:37.648740: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 12883915840427824154\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 32647086080\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 10116416161925150891\n",
      "physical_device_desc: \"device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:18:00.0, compute capability: 7.0\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-14 09:48:55.773654: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:0 with 31134 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:18:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import torch.nn as nn\n",
    "import logging\n",
    "import pandas as pd\n",
    "import csv\n",
    "import sys\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score \n",
    "from keras import backend as K\n",
    "import os\n",
    "from os.path import exists\n",
    "#import tensorflow_addons as tfa\n",
    "import shutil\n",
    "#from dual_finder import DualFinder, loadModelClass\n",
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "print(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")\n",
    "print(tf.config.list_physical_devices())\n",
    "from tensorflow.python.client import device_lib \n",
    "print(device_lib.list_local_devices())\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "from astropy.io import fits\n",
    "\n",
    "sys.path.append(\"DRAGON_Dual_Finder/dual_finder/cnn/\")\n",
    "sys.path.append(\"DRAGON_Dual_Finder/dual_finder/optimize/\")\n",
    "sys.path.append(\"DRAGON_Dual_Finder/dual_finder/preprocess_data/\")\n",
    "sys.path.append(\"DRAGON_Dual_Finder/dual_finder/visualize/\")\n",
    "from create_cnn import ModelCreator\n",
    "from load_model import loadModelClass\n",
    "from train_cnn import DualFinder\n",
    "from extract_feature_maps import FeatureExtractor\n",
    "from fits_utils import plot_dataset_sample\n",
    "from process_data import make_datasets_other_bands, create_dataset\n",
    "from optimize_hyperparameters import OptimizeHyperparameters\n",
    "from visualize_performance import load_training_history, plot_training_progress, plot_grouped_training_progress, VisualizeOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c39798e5-2783-45f4-ae16-b5f1ad4c5ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-14 09:48:57,505 - INFO - Loading images from data_preprocessing/training_datasets/empty_space_dataset/empty_space_train_data/ with label empty_sky...\n",
      "100%|██████████| 9215/9215 [00:39<00:00, 230.45it/s]\n",
      "0it [00:00, ?it/s]2024-06-14 09:49:38.073264: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31134 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:18:00.0, compute capability: 7.0\n",
      "9215it [00:55, 165.57it/s]\n",
      "2024-06-14 09:50:35,293 - INFO - Loading images from data_preprocessing/training_datasets/single_AGN_datasets/confirmed_single_AGN/ with label single_AGN...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 36860 images with 36860 labels from data_preprocessing/training_datasets/empty_space_dataset/empty_space_train_data/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:08<00:00, 226.17it/s]\n",
      "2000it [00:20, 99.98it/s] \n",
      "2024-06-14 09:51:04,775 - INFO - Loading images from data_preprocessing/training_datasets/dual_AGN_datasets/train_data/ with label dual_AGN...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 12000 images with 12000 labels from data_preprocessing/training_datasets/single_AGN_datasets/confirmed_single_AGN/\n",
      "Length of single AGN images: 12000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35492/35492 [01:43<00:00, 344.56it/s]\n",
      "2024-06-14 09:52:49,437 - INFO - expanding dims\n",
      "2024-06-14 09:52:49,438 - INFO - Loading images from data_preprocessing/training_datasets/offset_AGN_datasets/train_data/ with label offset_AGN...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 35492 images with 35492 labels from data_preprocessing/training_datasets/dual_AGN_datasets/train_data/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28756/28756 [01:42<00:00, 279.52it/s]\n",
      "2024-06-14 09:54:33,427 - INFO - expanding dims\n",
      "2024-06-14 09:54:33,428 - INFO - Loading images from data_preprocessing/training_datasets/stellar_dataset/train_data/ with label star_AGN_align...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 28756 images with 28756 labels from data_preprocessing/training_datasets/offset_AGN_datasets/train_data/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 16995/28319 [01:04<00:39, 287.75it/s]WARNING: File may have been truncated: actual file length (38224) is smaller than the expected size (40320) [astropy.io.fits.file]\n",
      "2024-06-14 09:55:38,960 - WARNING - File may have been truncated: actual file length (38224) is smaller than the expected size (40320)\n",
      "100%|██████████| 28319/28319 [01:48<00:00, 261.61it/s]\n",
      "2024-06-14 09:56:22,900 - INFO - expanding dims\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 28319 images with 28319 labels from data_preprocessing/training_datasets/stellar_dataset/train_data/\n",
      "Length of stellar images: (28319, 94, 94)\n",
      "Total images: (141427, 94, 94, 1)\n",
      "Total labels: (141427,)\n",
      "Total filepaths: (141427,)\n",
      "Train_dataset: (91927, 94, 94, 1)\n",
      "Train_labels: (91927,)\n",
      "Train_filepaths: (91927,)\n",
      "Val_dataset: (28285, 94, 94, 1)\n",
      "Val_labels: (28285,)\n",
      "Val_filepaths: (28285,)\n",
      "Test_dataset: (21215, 94, 94, 1)\n",
      "Test_labels: (21215,)\n",
      "Test_filepaths: (21215,)\n"
     ]
    }
   ],
   "source": [
    "#os.chdir(\"~/\")\n",
    "#!pwd\n",
    "empty_sky_filepath = \"data_preprocessing/training_datasets/empty_space_dataset/empty_space_train_data/\"\n",
    "single_AGN_filepath = \"data_preprocessing/training_datasets/single_AGN_datasets/confirmed_single_AGN/\"\n",
    "dual_AGN_filepath = \"data_preprocessing/training_datasets/dual_AGN_datasets/train_data/\"\n",
    "offset_AGN_filepath = 'data_preprocessing/training_datasets/offset_AGN_datasets/train_data/'\n",
    "stellar_filepath = \"data_preprocessing/training_datasets/stellar_dataset/train_data/\"\n",
    "train_data_labels, val_data_labels, test_data_labels = create_dataset(empty_sky_filepath = empty_sky_filepath,\n",
    "                                                                      dual_image_filepath = dual_AGN_filepath,\n",
    "                                                                      stellar_filepath = stellar_filepath,\n",
    "                                                                     offset_image_filepath = offset_AGN_filepath,\n",
    "                                                                     single_image_filepath = single_AGN_filepath)\n",
    "train_dataset, train_labels, train_filepaths = train_data_labels\n",
    "val_dataset, val_labels, val_filepaths = val_data_labels\n",
    "test_dataset, test_labels, test_filepaths = test_data_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7df448ee-c3c5-49dd-b7bd-53714e01b981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28285, 94, 94, 1)\n",
      "(28285,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(val_dataset))\n",
    "print(np.shape(val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78202199-0208-469f-a93d-8e6dd32a0945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dual_AGN' 'offset_AGN' 'offset_AGN' ... 'star_AGN_align' 'dual_AGN'\n",
      " 'empty_sky']\n",
      "['offset_AGN' 'offset_AGN' 'offset_AGN' ... 'empty_sky' 'offset_AGN'\n",
      " 'dual_AGN']\n",
      "Converting to list\n",
      "Converting to list\n",
      "train_labels shape: (91927, 5)\n",
      "val_labels shape: (28285, 5)\n",
      "Unique train labels: [0. 1.]\n",
      "Unique val labels: [0. 1.]\n",
      "5\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_1 (Rescaling)     (None, 94, 94, 1)         0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 94, 94, 64)        640       \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 94, 94, 64)        0         \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, 94, 94, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " average_pooling2d_3 (Avera  (None, 47, 47, 64)        0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 47, 47, 96)        55392     \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 47, 47, 96)        0         \n",
      "                                                                 \n",
      " batch_normalization_8 (Bat  (None, 47, 47, 96)        384       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " average_pooling2d_4 (Avera  (None, 23, 23, 96)        0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 23, 23, 128)       110720    \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 23, 23, 128)       0         \n",
      "                                                                 \n",
      " batch_normalization_9 (Bat  (None, 23, 23, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 23, 23, 256)       295168    \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 23, 23, 256)       0         \n",
      "                                                                 \n",
      " batch_normalization_10 (Ba  (None, 23, 23, 256)       1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 23, 23, 384)       885120    \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 23, 23, 384)       0         \n",
      "                                                                 \n",
      " batch_normalization_11 (Ba  (None, 23, 23, 384)       1536      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 23, 23, 384)       1327488   \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 23, 23, 384)       0         \n",
      "                                                                 \n",
      " batch_normalization_12 (Ba  (None, 23, 23, 384)       1536      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 23, 23, 512)       1769984   \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 23, 23, 512)       0         \n",
      "                                                                 \n",
      " batch_normalization_13 (Ba  (None, 23, 23, 512)       2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " average_pooling2d_5 (Avera  (None, 11, 11, 512)       0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 61952)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1024)              63439872  \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 5)                 5125      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67896805 (259.01 MB)\n",
      "Trainable params: 67893157 (258.99 MB)\n",
      "Non-trainable params: 3648 (14.25 KB)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_1 (Rescaling)     (None, 94, 94, 1)         0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 94, 94, 64)        640       \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 94, 94, 64)        0         \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, 94, 94, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " average_pooling2d_3 (Avera  (None, 47, 47, 64)        0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 47, 47, 96)        55392     \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 47, 47, 96)        0         \n",
      "                                                                 \n",
      " batch_normalization_8 (Bat  (None, 47, 47, 96)        384       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " average_pooling2d_4 (Avera  (None, 23, 23, 96)        0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 23, 23, 128)       110720    \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 23, 23, 128)       0         \n",
      "                                                                 \n",
      " batch_normalization_9 (Bat  (None, 23, 23, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 23, 23, 256)       295168    \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 23, 23, 256)       0         \n",
      "                                                                 \n",
      " batch_normalization_10 (Ba  (None, 23, 23, 256)       1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 23, 23, 384)       885120    \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 23, 23, 384)       0         \n",
      "                                                                 \n",
      " batch_normalization_11 (Ba  (None, 23, 23, 384)       1536      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 23, 23, 384)       1327488   \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 23, 23, 384)       0         \n",
      "                                                                 \n",
      " batch_normalization_12 (Ba  (None, 23, 23, 384)       1536      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 23, 23, 512)       1769984   \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 23, 23, 512)       0         \n",
      "                                                                 \n",
      " batch_normalization_13 (Ba  (None, 23, 23, 512)       2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " average_pooling2d_5 (Avera  (None, 11, 11, 512)       0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 61952)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1024)              63439872  \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 5)                 5125      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67896805 (259.01 MB)\n",
      "Trainable params: 67893157 (258.99 MB)\n",
      "Non-trainable params: 3648 (14.25 KB)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-14 10:19:41,930 - INFO - 'save_feature_maps' == False, NOT saving feature maps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images shape: (91927, 94, 94, 1)\n",
      "train_labels shape: (91927, 5)\n",
      "val_images shape: (28285, 94, 94, 1)\n",
      "val_labels shape: (28285, 5)\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-14 10:19:47.609402: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_1/dropout_8/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2873/2873 [==============================] - ETA: 0s - loss: 25.7746 - accuracy: 0.9604 - precision: 0.9678 - recall: 0.9528 - f1_score: 0.9470INFO:tensorflow:Assets written to: ../saved_dual_finder_models/_checkpoint_training/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-14 10:22:07,352 - INFO - Assets written to: ../saved_dual_finder_models/_checkpoint_training/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2873/2873 [==============================] - 142s 48ms/step - loss: 25.7746 - accuracy: 0.9604 - precision: 0.9678 - recall: 0.9528 - f1_score: 0.9470 - val_loss: 20.1359 - val_accuracy: 0.5165 - val_precision: 0.5188 - val_recall: 0.5104 - val_f1_score: 0.4611\n",
      "Epoch 2/20\n",
      "2872/2873 [============================>.] - ETA: 0s - loss: 13.9479 - accuracy: 0.9885 - precision: 0.9889 - recall: 0.9882 - f1_score: 0.9837INFO:tensorflow:Assets written to: ../saved_dual_finder_models/_checkpoint_training/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-14 10:24:23,426 - INFO - Assets written to: ../saved_dual_finder_models/_checkpoint_training/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2873/2873 [==============================] - 136s 47ms/step - loss: 13.9470 - accuracy: 0.9885 - precision: 0.9889 - recall: 0.9883 - f1_score: 0.9838 - val_loss: 19.3733 - val_accuracy: 0.5065 - val_precision: 0.5075 - val_recall: 0.5061 - val_f1_score: 0.3901\n",
      "Epoch 3/20\n",
      "2873/2873 [==============================] - ETA: 0s - loss: 8.3698 - accuracy: 0.9924 - precision: 0.9926 - recall: 0.9921 - f1_score: 0.9889INFO:tensorflow:Assets written to: ../saved_dual_finder_models/_checkpoint_training/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-14 10:26:39,835 - INFO - Assets written to: ../saved_dual_finder_models/_checkpoint_training/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2873/2873 [==============================] - 136s 47ms/step - loss: 8.3698 - accuracy: 0.9924 - precision: 0.9926 - recall: 0.9921 - f1_score: 0.9889 - val_loss: 9.3306 - val_accuracy: 0.5584 - val_precision: 0.5589 - val_recall: 0.5576 - val_f1_score: 0.4836\n",
      "Epoch 4/20\n",
      "2873/2873 [==============================] - ETA: 0s - loss: 5.2559 - accuracy: 0.9943 - precision: 0.9944 - recall: 0.9941 - f1_score: 0.9918INFO:tensorflow:Assets written to: ../saved_dual_finder_models/_checkpoint_training/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-14 10:28:55,809 - INFO - Assets written to: ../saved_dual_finder_models/_checkpoint_training/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2873/2873 [==============================] - 136s 47ms/step - loss: 5.2559 - accuracy: 0.9943 - precision: 0.9944 - recall: 0.9941 - f1_score: 0.9918 - val_loss: 4.2131 - val_accuracy: 0.9707 - val_precision: 0.9709 - val_recall: 0.9704 - val_f1_score: 0.9587\n",
      "Epoch 5/20\n",
      "2873/2873 [==============================] - ETA: 0s - loss: 3.3931 - accuracy: 0.9950 - precision: 0.9951 - recall: 0.9950 - f1_score: 0.9928INFO:tensorflow:Assets written to: ../saved_dual_finder_models/_checkpoint_training/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-14 10:31:12,240 - INFO - Assets written to: ../saved_dual_finder_models/_checkpoint_training/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2873/2873 [==============================] - 136s 47ms/step - loss: 3.3931 - accuracy: 0.9950 - precision: 0.9951 - recall: 0.9950 - f1_score: 0.9928 - val_loss: 2.7002 - val_accuracy: 0.9965 - val_precision: 0.9967 - val_recall: 0.9965 - val_f1_score: 0.9960\n",
      "Epoch 6/20\n",
      "2873/2873 [==============================] - ETA: 0s - loss: 2.1940 - accuracy: 0.9958 - precision: 0.9959 - recall: 0.9958 - f1_score: 0.9940INFO:tensorflow:Assets written to: ../saved_dual_finder_models/_checkpoint_training/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-14 10:33:28,255 - INFO - Assets written to: ../saved_dual_finder_models/_checkpoint_training/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2873/2873 [==============================] - 136s 47ms/step - loss: 2.1940 - accuracy: 0.9958 - precision: 0.9959 - recall: 0.9958 - f1_score: 0.9940 - val_loss: 1.8875 - val_accuracy: 0.9734 - val_precision: 0.9736 - val_recall: 0.9727 - val_f1_score: 0.9652\n",
      "Epoch 7/20\n",
      "2872/2873 [============================>.] - ETA: 0s - loss: 1.4809 - accuracy: 0.9961 - precision: 0.9961 - recall: 0.9960 - f1_score: 0.9943INFO:tensorflow:Assets written to: ../saved_dual_finder_models/_checkpoint_training/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-14 10:35:44,600 - INFO - Assets written to: ../saved_dual_finder_models/_checkpoint_training/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2873/2873 [==============================] - 136s 47ms/step - loss: 1.4809 - accuracy: 0.9961 - precision: 0.9961 - recall: 0.9960 - f1_score: 0.9943 - val_loss: 1.2055 - val_accuracy: 0.9989 - val_precision: 0.9990 - val_recall: 0.9989 - val_f1_score: 0.9985\n",
      "Epoch 8/20\n",
      "2873/2873 [==============================] - ETA: 0s - loss: 1.0060 - accuracy: 0.9967 - precision: 0.9967 - recall: 0.9966 - f1_score: 0.9953INFO:tensorflow:Assets written to: ../saved_dual_finder_models/_checkpoint_training/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-14 10:38:00,673 - INFO - Assets written to: ../saved_dual_finder_models/_checkpoint_training/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2873/2873 [==============================] - 136s 47ms/step - loss: 1.0060 - accuracy: 0.9967 - precision: 0.9967 - recall: 0.9966 - f1_score: 0.9953 - val_loss: 0.8767 - val_accuracy: 0.9804 - val_precision: 0.9811 - val_recall: 0.9803 - val_f1_score: 0.9730\n",
      "Epoch 9/20\n",
      "2873/2873 [==============================] - ETA: 0s - loss: 0.7094 - accuracy: 0.9964 - precision: 0.9965 - recall: 0.9963 - f1_score: 0.9949INFO:tensorflow:Assets written to: ../saved_dual_finder_models/_checkpoint_training/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-14 10:40:17,168 - INFO - Assets written to: ../saved_dual_finder_models/_checkpoint_training/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2873/2873 [==============================] - 136s 48ms/step - loss: 0.7094 - accuracy: 0.9964 - precision: 0.9965 - recall: 0.9963 - f1_score: 0.9949 - val_loss: 0.5936 - val_accuracy: 0.9977 - val_precision: 0.9977 - val_recall: 0.9974 - val_f1_score: 0.9972\n",
      "Epoch 10/20\n",
      "2873/2873 [==============================] - ETA: 0s - loss: 0.5092 - accuracy: 0.9972 - precision: 0.9973 - recall: 0.9972 - f1_score: 0.9961INFO:tensorflow:Assets written to: ../saved_dual_finder_models/_checkpoint_training/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-14 10:42:33,201 - INFO - Assets written to: ../saved_dual_finder_models/_checkpoint_training/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2873/2873 [==============================] - 136s 47ms/step - loss: 0.5092 - accuracy: 0.9972 - precision: 0.9973 - recall: 0.9972 - f1_score: 0.9961 - val_loss: 4.0640 - val_accuracy: 0.5726 - val_precision: 0.5740 - val_recall: 0.5707 - val_f1_score: 0.5085\n",
      "Epoch 11/20\n",
      "1349/2873 [=============>................] - ETA: 1:05 - loss: 0.4074 - accuracy: 0.9974 - precision: 0.9975 - recall: 0.9974 - f1_score: 0.9962"
     ]
    }
   ],
   "source": [
    "image_shape = (94,94,1)\n",
    "epoch = 20\n",
    "batch_size = 64\n",
    "init_learning_rate = 1e-5\n",
    "num_classes = 5\n",
    "model_type = 'dualfinder'\n",
    "importance_score = [1.0, 1.0]\n",
    "\n",
    "dual_finder_instance = DualFinder(train_dataset, val_dataset, image_shape, train_labels, val_labels, epoch, batch_size, init_learning_rate, num_classes, model_type, importance_score, display_architecture = True)\n",
    "history, dual_finder_model = dual_finder_instance.trainCNN(save_feature_maps = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea61372-5523-4530-ac9b-d0ae22fd4511",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(history)\n",
    "#print(type(history))\n",
    "#print(history.history)\n",
    "accuracy = history.history['accuracy']\n",
    "loss = history.history['loss']\n",
    "precision = history.history['precision']\n",
    "recall = history.history['recall']\n",
    "f1score = history.history['f1_score']\n",
    "\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "val_loss = history.history['val_loss']\n",
    "val_precision = history.history['val_precision']\n",
    "val_recall = history.history['val_recall']\n",
    "val_f1score = history.history['val_f1_score']\n",
    "training_epochs = np.arange(0, epoch)\n",
    "fig_save_filepath = 'DRAGON_Dual_Finder/saved_training_figures/'\n",
    "if not exists(fig_save_filepath):\n",
    "    os.makedirs(fig_save_filepath)\n",
    "fig, ax = plot_training_progress(loss, accuracy, training_epochs, save_filepath = fig_save_filepath, training_run = \"DRAGON DualFinder\",\n",
    "                                 recall = recall, precision = precision, f1_score = f1score,\n",
    "                                 val_loss = val_loss, val_acc = val_accuracy, val_recall = val_recall, val_precision = val_precision, \n",
    "                                 val_f1_score = val_f1score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de631d23-d01f-4761-892b-da8c15375e7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eval_labels_encoded, _ = dual_finder_instance.encode_labels(test_labels, test_labels)\n",
    "dual_finder_model.evaluate(test_dataset, eval_labels_encoded, batch_size = batch_size, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19abc843-36d2-4735-b5c5-7a571e29daaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(\"data_preprocessing/training_datasets/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8b1b0e-16a7-484f-b28e-922bcffa4ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dual_finder_instance.predict(dual_finder_model, test_dataset, test_filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc75a881-2509-48be-87b9-2459105b139f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678b79da-be77-41d1-b455-e3bd3beb82b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
